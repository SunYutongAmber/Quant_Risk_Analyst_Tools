{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('DailyPrices.csv')\n",
    "date = df['Date']\n",
    "prices = df.iloc[:,1:] #drop the first column of date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Return Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2n/lm0km0mn4zlf79tvv2679h740000gn/T/ipykernel_70379/545654781.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pct_change[column] = (df[column].diff()/df[column].shift(1))[1:]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SPY</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>MSFT</th>\n",
       "      <th>AMZN</th>\n",
       "      <th>NVDA</th>\n",
       "      <th>GOOGL</th>\n",
       "      <th>TSLA</th>\n",
       "      <th>GOOG</th>\n",
       "      <th>BRK-B</th>\n",
       "      <th>META</th>\n",
       "      <th>...</th>\n",
       "      <th>CI</th>\n",
       "      <th>ETN</th>\n",
       "      <th>SLB</th>\n",
       "      <th>PGR</th>\n",
       "      <th>SCHW</th>\n",
       "      <th>LRCX</th>\n",
       "      <th>ZTS</th>\n",
       "      <th>C</th>\n",
       "      <th>BSX</th>\n",
       "      <th>AMT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.010544</td>\n",
       "      <td>-0.013611</td>\n",
       "      <td>-0.016667</td>\n",
       "      <td>-0.002425</td>\n",
       "      <td>-0.020808</td>\n",
       "      <td>-0.017223</td>\n",
       "      <td>-0.025076</td>\n",
       "      <td>-0.016915</td>\n",
       "      <td>-0.016854</td>\n",
       "      <td>-0.030479</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001180</td>\n",
       "      <td>-0.010593</td>\n",
       "      <td>0.033107</td>\n",
       "      <td>-0.010428</td>\n",
       "      <td>-0.019242</td>\n",
       "      <td>-0.004236</td>\n",
       "      <td>-0.015244</td>\n",
       "      <td>0.001846</td>\n",
       "      <td>-0.012198</td>\n",
       "      <td>-0.026355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.003773</td>\n",
       "      <td>-0.008215</td>\n",
       "      <td>-0.010974</td>\n",
       "      <td>-0.010980</td>\n",
       "      <td>-0.013336</td>\n",
       "      <td>-0.009643</td>\n",
       "      <td>0.015581</td>\n",
       "      <td>-0.011042</td>\n",
       "      <td>-0.003890</td>\n",
       "      <td>-0.011103</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004641</td>\n",
       "      <td>0.008449</td>\n",
       "      <td>-0.014118</td>\n",
       "      <td>0.000572</td>\n",
       "      <td>0.001848</td>\n",
       "      <td>-0.008019</td>\n",
       "      <td>-0.000892</td>\n",
       "      <td>-0.012695</td>\n",
       "      <td>-0.002717</td>\n",
       "      <td>0.013275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.017965</td>\n",
       "      <td>0.009254</td>\n",
       "      <td>0.019111</td>\n",
       "      <td>0.026723</td>\n",
       "      <td>0.018795</td>\n",
       "      <td>0.024717</td>\n",
       "      <td>0.033817</td>\n",
       "      <td>0.027912</td>\n",
       "      <td>0.016089</td>\n",
       "      <td>0.011669</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016652</td>\n",
       "      <td>0.020295</td>\n",
       "      <td>-0.008030</td>\n",
       "      <td>0.038537</td>\n",
       "      <td>0.018731</td>\n",
       "      <td>0.012279</td>\n",
       "      <td>0.022698</td>\n",
       "      <td>0.008503</td>\n",
       "      <td>0.026994</td>\n",
       "      <td>0.020930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.006536</td>\n",
       "      <td>-0.009618</td>\n",
       "      <td>0.001666</td>\n",
       "      <td>0.002626</td>\n",
       "      <td>0.020126</td>\n",
       "      <td>-0.009776</td>\n",
       "      <td>0.019598</td>\n",
       "      <td>-0.009595</td>\n",
       "      <td>0.008184</td>\n",
       "      <td>0.010412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002448</td>\n",
       "      <td>0.013945</td>\n",
       "      <td>0.029951</td>\n",
       "      <td>0.015880</td>\n",
       "      <td>0.019083</td>\n",
       "      <td>0.016574</td>\n",
       "      <td>-0.011908</td>\n",
       "      <td>0.026116</td>\n",
       "      <td>0.029901</td>\n",
       "      <td>0.008362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.015535</td>\n",
       "      <td>0.018840</td>\n",
       "      <td>0.022977</td>\n",
       "      <td>0.026575</td>\n",
       "      <td>0.028377</td>\n",
       "      <td>0.020945</td>\n",
       "      <td>0.036023</td>\n",
       "      <td>0.021568</td>\n",
       "      <td>0.008576</td>\n",
       "      <td>0.043749</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007327</td>\n",
       "      <td>0.017244</td>\n",
       "      <td>0.038774</td>\n",
       "      <td>-0.004179</td>\n",
       "      <td>0.018863</td>\n",
       "      <td>0.026460</td>\n",
       "      <td>0.036721</td>\n",
       "      <td>0.015431</td>\n",
       "      <td>0.005385</td>\n",
       "      <td>-0.000306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>0.000586</td>\n",
       "      <td>0.016913</td>\n",
       "      <td>-0.003513</td>\n",
       "      <td>-0.002920</td>\n",
       "      <td>0.001503</td>\n",
       "      <td>0.005895</td>\n",
       "      <td>-0.033201</td>\n",
       "      <td>0.004772</td>\n",
       "      <td>0.006986</td>\n",
       "      <td>0.007459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007485</td>\n",
       "      <td>0.006938</td>\n",
       "      <td>0.010399</td>\n",
       "      <td>0.013118</td>\n",
       "      <td>-0.006183</td>\n",
       "      <td>0.020125</td>\n",
       "      <td>-0.003329</td>\n",
       "      <td>-0.001639</td>\n",
       "      <td>0.001890</td>\n",
       "      <td>-0.003386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>-0.002074</td>\n",
       "      <td>0.006181</td>\n",
       "      <td>-0.001246</td>\n",
       "      <td>-0.016788</td>\n",
       "      <td>-0.010144</td>\n",
       "      <td>-0.001230</td>\n",
       "      <td>0.004599</td>\n",
       "      <td>-0.000936</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.008329</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002453</td>\n",
       "      <td>-0.013644</td>\n",
       "      <td>-0.012743</td>\n",
       "      <td>0.013589</td>\n",
       "      <td>-0.002247</td>\n",
       "      <td>-0.016519</td>\n",
       "      <td>0.012970</td>\n",
       "      <td>0.000938</td>\n",
       "      <td>0.000566</td>\n",
       "      <td>-0.012087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>-0.009193</td>\n",
       "      <td>-0.019992</td>\n",
       "      <td>-0.023977</td>\n",
       "      <td>-0.017002</td>\n",
       "      <td>-0.029435</td>\n",
       "      <td>-0.031150</td>\n",
       "      <td>-0.014672</td>\n",
       "      <td>-0.030541</td>\n",
       "      <td>-0.009879</td>\n",
       "      <td>-0.017701</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009450</td>\n",
       "      <td>-0.006986</td>\n",
       "      <td>-0.010591</td>\n",
       "      <td>0.001544</td>\n",
       "      <td>-0.018361</td>\n",
       "      <td>-0.010062</td>\n",
       "      <td>-0.002748</td>\n",
       "      <td>-0.008903</td>\n",
       "      <td>0.020177</td>\n",
       "      <td>0.000282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>-0.016528</td>\n",
       "      <td>-0.008889</td>\n",
       "      <td>-0.003866</td>\n",
       "      <td>-0.044053</td>\n",
       "      <td>-0.028931</td>\n",
       "      <td>-0.024675</td>\n",
       "      <td>-0.026239</td>\n",
       "      <td>-0.023999</td>\n",
       "      <td>-0.009651</td>\n",
       "      <td>-0.013148</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012216</td>\n",
       "      <td>-0.018635</td>\n",
       "      <td>-0.016223</td>\n",
       "      <td>-0.002032</td>\n",
       "      <td>-0.011646</td>\n",
       "      <td>-0.013686</td>\n",
       "      <td>-0.026725</td>\n",
       "      <td>-0.013948</td>\n",
       "      <td>-0.002403</td>\n",
       "      <td>-0.045601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>-0.002249</td>\n",
       "      <td>0.004945</td>\n",
       "      <td>-0.007887</td>\n",
       "      <td>-0.001624</td>\n",
       "      <td>0.014457</td>\n",
       "      <td>-0.001457</td>\n",
       "      <td>-0.042315</td>\n",
       "      <td>-0.000837</td>\n",
       "      <td>-0.008588</td>\n",
       "      <td>0.011328</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004814</td>\n",
       "      <td>0.009542</td>\n",
       "      <td>0.003740</td>\n",
       "      <td>0.006039</td>\n",
       "      <td>-0.015354</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.000283</td>\n",
       "      <td>-0.018940</td>\n",
       "      <td>-0.006856</td>\n",
       "      <td>-0.018368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>265 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          SPY      AAPL      MSFT      AMZN      NVDA     GOOGL      TSLA  \\\n",
       "1   -0.010544 -0.013611 -0.016667 -0.002425 -0.020808 -0.017223 -0.025076   \n",
       "2   -0.003773 -0.008215 -0.010974 -0.010980 -0.013336 -0.009643  0.015581   \n",
       "3    0.017965  0.009254  0.019111  0.026723  0.018795  0.024717  0.033817   \n",
       "4    0.006536 -0.009618  0.001666  0.002626  0.020126 -0.009776  0.019598   \n",
       "5    0.015535  0.018840  0.022977  0.026575  0.028377  0.020945  0.036023   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "261  0.000586  0.016913 -0.003513 -0.002920  0.001503  0.005895 -0.033201   \n",
       "262 -0.002074  0.006181 -0.001246 -0.016788 -0.010144 -0.001230  0.004599   \n",
       "263 -0.009193 -0.019992 -0.023977 -0.017002 -0.029435 -0.031150 -0.014672   \n",
       "264 -0.016528 -0.008889 -0.003866 -0.044053 -0.028931 -0.024675 -0.026239   \n",
       "265 -0.002249  0.004945 -0.007887 -0.001624  0.014457 -0.001457 -0.042315   \n",
       "\n",
       "         GOOG     BRK-B      META  ...        CI       ETN       SLB  \\\n",
       "1   -0.016915 -0.016854 -0.030479  ... -0.001180 -0.010593  0.033107   \n",
       "2   -0.011042 -0.003890 -0.011103  ... -0.004641  0.008449 -0.014118   \n",
       "3    0.027912  0.016089  0.011669  ...  0.016652  0.020295 -0.008030   \n",
       "4   -0.009595  0.008184  0.010412  ...  0.002448  0.013945  0.029951   \n",
       "5    0.021568  0.008576  0.043749  ...  0.007327  0.017244  0.038774   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "261  0.004772  0.006986  0.007459  ...  0.007485  0.006938  0.010399   \n",
       "262 -0.000936  0.000135  0.008329  ... -0.002453 -0.013644 -0.012743   \n",
       "263 -0.030541 -0.009879 -0.017701  ...  0.009450 -0.006986 -0.010591   \n",
       "264 -0.023999 -0.009651 -0.013148  ...  0.012216 -0.018635 -0.016223   \n",
       "265 -0.000837 -0.008588  0.011328  ... -0.004814  0.009542  0.003740   \n",
       "\n",
       "          PGR      SCHW      LRCX       ZTS         C       BSX       AMT  \n",
       "1   -0.010428 -0.019242 -0.004236 -0.015244  0.001846 -0.012198 -0.026355  \n",
       "2    0.000572  0.001848 -0.008019 -0.000892 -0.012695 -0.002717  0.013275  \n",
       "3    0.038537  0.018731  0.012279  0.022698  0.008503  0.026994  0.020930  \n",
       "4    0.015880  0.019083  0.016574 -0.011908  0.026116  0.029901  0.008362  \n",
       "5   -0.004179  0.018863  0.026460  0.036721  0.015431  0.005385 -0.000306  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "261  0.013118 -0.006183  0.020125 -0.003329 -0.001639  0.001890 -0.003386  \n",
       "262  0.013589 -0.002247 -0.016519  0.012970  0.000938  0.000566 -0.012087  \n",
       "263  0.001544 -0.018361 -0.010062 -0.002748 -0.008903  0.020177  0.000282  \n",
       "264 -0.002032 -0.011646 -0.013686 -0.026725 -0.013948 -0.002403 -0.045601  \n",
       "265  0.006039 -0.015354  0.014286  0.000283 -0.018940 -0.006856 -0.018368  \n",
       "\n",
       "[265 rows x 101 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def return_calculation(df):\n",
    "    pct_change = pd.DataFrame()\n",
    "    for column in prices.columns:\n",
    "        pct_change[column] = (df[column].diff()/df[column].shift(1))[1:]\n",
    "    return pct_change\n",
    "return_df = return_calculation(prices)\n",
    "return_df.to_csv('return_df')\n",
    "return_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VaR calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_var(returns, alpha=0.05):\n",
    "    sorted_returns = np.sort(returns)\n",
    "    index = int(alpha * len(sorted_returns))\n",
    "    return -sorted_returns[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Normal Distribution Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2n/lm0km0mn4zlf79tvv2679h740000gn/T/ipykernel_70379/1932564048.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[column] = sim_normal_return\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SPY     0.018677\n",
       "AAPL    0.027738\n",
       "MSFT    0.029943\n",
       "AMZN    0.038534\n",
       "NVDA    0.051306\n",
       "          ...   \n",
       "LRCX    0.045275\n",
       "ZTS     0.027790\n",
       "C       0.027801\n",
       "BSX     0.022382\n",
       "AMT     0.027916\n",
       "Length: 101, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#normal distribution simulation\n",
    "df1 = pd.DataFrame()\n",
    "for column in return_df.columns:\n",
    "    m = np.mean(return_df[column]) #mean valkue of each stock\n",
    "    sd = np.std(return_df[column]) # standard deviation of each stock\n",
    "    sim_normal_return = np.random.normal(m, sd, len(return_df[column]))\n",
    "    df1[column] = sim_normal_return\n",
    "\n",
    "#VaR calculation using writen function\n",
    "var_list = []\n",
    "for column in df1.columns:\n",
    "    var_value = calculate_var(df1[column], alpha=0.05)\n",
    "    var_series = pd.Series([var_value], index=[column])\n",
    "    var_list.append(var_series)\n",
    "var_df = pd.concat(var_list, axis=0)\n",
    "var_df\n",
    "\n",
    "#VaR calculation using built-in percentile function\n",
    "var_list = []\n",
    "for column in df1.columns:\n",
    "    var_value = - np.percentile(df1[column],5) #5是分位数\n",
    "    var_series = pd.Series([var_value],index=[column])\n",
    "    var_list.append(var_series)\n",
    "var_df_builtin = pd.concat(var_list)\n",
    "var_df_builtin\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Historical VaR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SPY     0.016528\n",
       "AAPL    0.030039\n",
       "MSFT    0.025767\n",
       "AMZN    0.039792\n",
       "NVDA    0.040851\n",
       "          ...   \n",
       "LRCX    0.040174\n",
       "ZTS     0.024978\n",
       "C       0.028694\n",
       "BSX     0.018148\n",
       "AMT     0.031223\n",
       "Length: 101, dtype: float64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2 = []\n",
    "for column in return_df.columns:\n",
    "    var = calculate_var(return_df[column], alpha = 0.05)    \n",
    "    series = pd.Series([var], index=[column])\n",
    "    l2.append(series)\n",
    "var_df2 = pd.concat(l2)\n",
    "var_df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Exponentially Weighted VaR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#give exponential weighted data\n",
    "def ewCovar(x, lam):\n",
    "    m, n = x.shape\n",
    "    w = np.array([(1-lam)*lam**(m-i) for i in range(m)])\n",
    "    w /= np.sum(w)\n",
    "    xm = np.mean(x, axis=0)\n",
    "    x -= xm\n",
    "    return np.cov(x, aweights=w, rowvar=False)\n",
    "w_cov = ewCovar(return_df, 0.74)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Simulate T distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. AR simulation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ARIMA' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [52]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Example: AR(1) model fitting and simulation\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mARIMA\u001b[49m(meta, order\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m      3\u001b[0m model_fit \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(model_fit\u001b[38;5;241m.\u001b[39msummary())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ARIMA' is not defined"
     ]
    }
   ],
   "source": [
    "# Example: AR(1) model fitting and simulation\n",
    "model = ARIMA(meta, order=(1,0,0))\n",
    "model_fit = model.fit()\n",
    "print(model_fit.summary())\n",
    "\n",
    "innovations = np.random.normal(0, 1, 1000)\n",
    "ar_simulated = ar1_simulation(meta, model_fit.params, innovations)\n",
    "\n",
    "# VaR calculation for simulated data\n",
    "vaR_ar1 = calculate_var(ar_simulated)\n",
    "print(f\"AR(1) VaR: {vaR_ar1}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expected Shortfalls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
