{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maximum Likelihood Estimation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLE is used to maximize the likelihood of the joint probability of the apperance of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.optimize as opt\n",
    "from scipy.stats import norm, t\n",
    "\n",
    "def mle_fit(y, X, model_type):\n",
    "    def ll_normal(params, X, y):\n",
    "        b0, b1, e = params\n",
    "        y_pred = b0 + X * b1\n",
    "        residuals = y - y_pred\n",
    "        likelihood = np.sum(norm.logpdf(residuals, loc = 0, scale = e)) #e是error的标准差\n",
    "        return -likelihood\n",
    "\n",
    "    def ll_regression(params, X, y):\n",
    "        s = params[0]\n",
    "        beta = params[1:]\n",
    "        e = y - np.dot(X, beta)\n",
    "        return -np.sum(norm.logpdf(e, loc=0, scale=s))\n",
    "\n",
    "    def ll_t(params, X, y):\n",
    "        b0, b1, e, df = params\n",
    "        y_pred = b0 + b1 * X\n",
    "        residuals = y - y_pred\n",
    "        likelihood = np.sum(t.logpdf(residuals, df, loc = 0, scale = df))\n",
    "        return -likelihood\n",
    "\n",
    "    if model_type == 'normal':\n",
    "        result = opt.minimize(ll_normal, [0.0, 1.0, 1.0], args=(X[:,1], y), method='Nelder-Mead')\n",
    "    elif model_type == 'regression':\n",
    "        initial_guess = [1.0] + [0.0] * (X.shape[1])\n",
    "        result = opt.minimize(ll_regression, initial_guess, args=(X[:,1], y), method='Nelder-Mead')\n",
    "    elif model_type == 't':\n",
    "        result = opt.minimize(ll_t, [10, 0.0, 1.0, 1.0], args=(X[:,1], y), method='Nelder-Mead')\n",
    "    else:\n",
    "        raise ValueError(\"Invalid model type\")\n",
    "\n",
    "    return result\n",
    "# x：找到的最优解，即最小化目标函数时的参数值。\n",
    "# fun：在最优解处的目标函数值。\n",
    "# success：一个布尔值，表示优化过程是否成功。\n",
    "# message：关于优化过程的附加信息或退出状态的说明。\n",
    "# nit：执行的迭代次数。\n",
    "# jac（如果适用）：在最优解处的目标函数的梯度。\n",
    "# hess_inv（如果适用）：最优解处的目标函数的海森矩阵的逆。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " final_simplex: (array([[ -0.09034869,   0.57201994, -28.06004637,   0.87446691],\n",
       "       [ -0.09034751,   0.57202031, -28.06006575,   0.87446626],\n",
       "       [ -0.09034859,   0.57201816, -28.05995573,   0.87446666],\n",
       "       [ -0.0903476 ,   0.57201975, -28.06003646,   0.87446746],\n",
       "       [ -0.09034818,   0.57201819, -28.05995664,   0.87446748]]), array([327.95928387, 327.95928387, 327.95928387, 327.95928387,\n",
       "       327.95928387]))\n",
       "           fun: 327.95928386987214\n",
       "       message: 'Optimization terminated successfully.'\n",
       "          nfev: 457\n",
       "           nit: 266\n",
       "        status: 0\n",
       "       success: True\n",
       "             x: array([ -0.09034869,   0.57201994, -28.06004637,   0.87446691])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('problem2_545.csv')\n",
    "X = data['x'].values\n",
    "y = data['y'].values\n",
    "# Adding a constant term\n",
    "X = np.column_stack((np.ones(len(X)), X))\n",
    "\n",
    "mle_fit(y, X, 't')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_information_criteria(result, n):\n",
    "    \"\"\"\n",
    "    Calculate AIC, AICc, and BIC for a fitted model.\n",
    "\n",
    "    :param result: The result object returned from the minimize function.\n",
    "    :param n: The number of observations in the dataset.\n",
    "    :return: A tuple containing the AIC, AICc, and BIC values.\n",
    "    \"\"\"\n",
    "    k = len(result.x)  # The number of estimated parameters\n",
    "    ll = -result.fun  # The log-likelihood of the model\n",
    "    aic = 2 * k - 2 * ll\n",
    "    aicc = aic + (2 * k**2 + 2 * k) / (n - k - 1)\n",
    "    bic = np.log(n) * k - 2 * ll\n",
    "    \n",
    "    return aic, aicc, bic    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(663.9185677397443, 664.1236959448725, 677.1118372059365)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = mle_fit(y, X, 't')\n",
    "n = len(X)\n",
    "calculate_information_criteria(result, n)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
